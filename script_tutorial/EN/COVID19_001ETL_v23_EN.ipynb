{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis in R\n",
    "====================\n",
    "---\n",
    "Part 2 - Data preprocessing\n",
    "--------------------\n",
    "The First and the probably hardest part during data analysis is acquisition and preprocessing of data. There are many various ways, which allows for data collecting, f.e.:\n",
    "1. collecting from database\n",
    "2. downloading from websites - Web scraping\n",
    "3. using ResAPI (service which allows for communicating and f.e. data transfer)\n",
    "\n",
    "Before you start it is necessary to get some development environment. The dedicated solution is [RStudio](https://rstudio.com/#RStudio) for R language in the Windows ecosystem. This environment allows to get all necessary libraries automatically without problems with dependencies using your local computer. When you are using R Studio, you can copy commands from code fields.\n",
    "\n",
    "Additionally, this course was created in [Jupyter](https://jupyter.org/) environment, which can be used on AWS Sage Maker cloud for free with [AWS Free Tier](https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc). \n",
    "\n",
    "If you do not want to use cloud it is possible to do download all scripts and download [Anaconda](https://anaconda.org/), which integrates R interpreter with many various notebooks f.e. Jupyter, RStudio, Qt, Spyder.\n",
    "\n",
    "More details in part 1: `Development environment `.\n",
    "\n",
    "# 1. Installation and preparation to start\n",
    "## 1.1 Environment preparation\n",
    "Scripts written in this course were coded to allow working in production environment. Some steps were taken, which allows to deploy them in test environment.\n",
    "<br>\n",
    "The first step is to free memory and clean variables that could be used in previous iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#\n",
    "# INIT - INITIAL SECTION\n",
    "#\n",
    "#######################################################\n",
    "\n",
    "#clear terminal\n",
    "cat(\"\\f\")\n",
    "\n",
    "#clear all objects\n",
    "rm(list=ls())\n",
    "\n",
    "#clear memory\n",
    "gc() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Installation and loading of libraries\n",
    "It is necessary to install and load libraries before start of the scrip. There are all libraries used in the project:\n",
    "1. [utils](https://www.rdocumentation.org/packages/utils/versions/3.6.2)\n",
    "2. [fs](https://www.rdocumentation.org/packages/fs/versions/1.4.1) \n",
    "3. [zoo](https://cran.r-project.org/web/packages/zoo/index.html)\n",
    "4. [tidyverse](https://www.rdocumentation.org/packages/tidyverse/versions/1.3.0) \n",
    "5. [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) \n",
    "6. [data.table](https://www.rdocumentation.org/packages/data.table/versions/1.12.8) \n",
    "7. [httr](https://www.rdocumentation.org/packages/httr/versions/1.4.1) \n",
    "8. [lubridate](https://www.rdocumentation.org/packages/lubridate/versions/1.7.8) \n",
    "9. [readxl](https://www.rdocumentation.org/packages/readxl/versions/1.3.1) \n",
    "10. [jsonify](https://www.rdocumentation.org/packages/jsonify/versions/1.1.1) \n",
    "11. [reshape](https://www.rdocumentation.org/packages/reshape/versions/0.8.8)\n",
    "\n",
    "In the production environment, all libraries should be preinstalled and preloaded, so the next step will be omitted. This step needs to be done in the local environment, to load all libraries. There are additional conditional instructions, which checks if libraries are preinstalled, installations starts - `if(!require(libray_name))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#\n",
    "# INIT- LIBRARY SECTION\n",
    "#\n",
    "###############################\n",
    "\n",
    "#these libraries are necessary\n",
    "if(!require(\"utils\")) install.packages(\"utils\")\n",
    "library(utils)\n",
    "if(!require(\"fs\")) install.packages(\"fs\")\n",
    "library(fs)\n",
    "if(!require(\"zoo\")) install.packages(\"zoo\")             \n",
    "library(zoo)                  \n",
    "if(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n",
    "library(tidyverse)\n",
    "if(!require(\"dplyr\")) install.packages(\"dplyr\")\n",
    "library(dplyr)\n",
    "if(!require(\"data.table\")) install.packages(\"data.table\")\n",
    "library(data.table)\n",
    "if(!require(\"httr\")) install.packages(\"httr\")\n",
    "library(httr)\n",
    "if(!require(\"lubridate\")) install.packages(\"lubridate\")\n",
    "library(lubridate)\n",
    "if(!require(\"readxl\")) install.packages(\"readxl\")\n",
    "library(readxl)\n",
    "if(!require(\"jsonify\")) install.packages(\"jsonify\")\n",
    "library(jsonify)\n",
    "if(!require(\"reshape\")) install.packages(\"reshape\")\n",
    "library(reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Functions\n",
    "\n",
    "[Functions](https://www.tutorialspoint.com/r/r_functions.htm) allows to put repetitive parts of the program in smaller logical parts. It helps to have order in the code. In this script two functions were made:\n",
    "\n",
    "1. f_collapseColumns2Colection <br>\n",
    "    `f_collapseColumns2Colection <- function(df_add, key, nameColectColumn,nameNewColumn )` <br>\n",
    "    as arguments has df_add, key, nameColectColumn oraz nameNewColumn <br>\n",
    "    <br>\n",
    "1. f_orderColumnFinallDataSet <br>\n",
    "    Is used to create final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# INIT- FUNCTION AND SECTION\n",
    "\n",
    "#function for create colection from siutable countries\n",
    "f_collapseColumns2Colection <- function(df_add, key, nameColectColumn,nameNewColumn ){\n",
    "  data_colection <- df_add %>%\n",
    "    group_by_at(key) %>% \n",
    "    summarise_at(nameColectColumn,list)\n",
    "  \n",
    "  setnames( data_colection, nameColectColumn, nameNewColumn)\n",
    "  \n",
    "  df_add <- merge(x=df_add, y=data_colection, by = key , all.x=TRUE)\n",
    "  return(df_add)\n",
    "}\n",
    "\n",
    "#function for registration columns for finall data set\n",
    "f_orderColumnFinallDataSet <- function(nameOfVector){\n",
    "  \n",
    "  V_key       <- c(\"PK_countryID\", \"PK_dateReport1DayNatural\")  \n",
    "  v_country  <- c(\"countryOfficialName\", \"countryCommonName\", \"capital\", \"area\", \"countryGeoID\" , \"c_latlng\", \"lat\", \"lng\", \"c_neighbors\", \"region\", \"c_region\", \"subregion\", \"c_subregion\", \"c_groupDistance300\",\"c_groupDistance500\",\"c_groupDistance1000\",\"independent\")\n",
    "  \n",
    "  v_casesandaggregation <- c(\"cases1DayNatural\",\"mmeanCases1DayNatural\", \"cumSumCases1DayNatural\", \n",
    "                             \"sumCases7DayNaturalPrev7Day\", \"sumCases7DayNatural\", \"sumCases7DayNaturalNext7Day\", \"sumCases1MonthNatural\", \n",
    "                             \"avgCases7DayNaturalPrev7Day\", \"avgCases7DayNatural\", \"avgCases7DayNaturalNext7Day\", \"avgCases1MonthNatural\",\n",
    "                             \"quanCases7DayNaturalPrev7Day\", \"quanCases7DayNatural\", \"quanCases7DayNaturalNext7Day\", \"quanCases1MonthNatural\")    \n",
    "  \n",
    "  v_deathsandaggregation <- c(\"deaths1DayNatural\", \"mmeanDeath1DayNatural\", \"cumSumDeath1DayNatural\",\n",
    "                              \"sumDeaths7DayNaturalPrev7Day\", \"sumDeaths7DayNatural\", \"sumDeaths7DayNaturalNext7Day\", \"sumDeaths1MonthNatural\",\n",
    "                              \"avgDeaths7DayNaturalPrev7Day\", \"avgDeaths7DayNatural\", \"avgDeaths7DayNaturalNext7Day\", \"avgDeaths1MonthNatural\",\n",
    "                              \"quanDeaths7DayNaturalPrev7Day\",  \"quanDeaths7DayNatural\", \"quanDeaths7DayNaturalNext7Day\", \"quanDeaths1MonthNatural\")\n",
    "  \n",
    "  V_population   <- c(\"population2018_A\", \n",
    "                      \"population2018_A_70\", \"population2018_F_70\",\"population2018_M_70\",  \n",
    "                      \"population2018_A_80\", \"population2018_F_80\", \"population2018_M_80\")\n",
    "  v_otherIndicator <-c(\"GDP_US\")\n",
    "  \n",
    "  V_indexNatural <-  c(\"index1DayNatural\",  \"index7DayNatural\", \"index1MonthNatural\", \"index1YearNatural\")  \n",
    "  V_indexCases   <-  c(\"index1Day1Case\", \"index7Day1Case\", \"index1Day10cumSumCaseP100t_A_70\", \"index1Day10cumSumCaseP1mAll\",   \"index7Day10cumSumCaseP100t_A_70\", \"index7Day10cumSumCaseP1mAll\")                    \n",
    "  V_indexDeath   <-  c(\"index1Day1Death\", \"index7Day1Death\", \"index1Day1cumSumDeathP100t_A_70\", \"index1Day1cumSumDeathP1mAll\", \"index7Day1cumSumDeathP100t_A_70\", \"index7Day1cumSumDeathP1mAll\")   \n",
    "  \n",
    "  v_country_SUM <- c(\"PK_countryID\", v_country, V_population,v_otherIndicator )\n",
    "  v_order_column_SUM <- c(V_key,v_country, v_casesandaggregation, v_deathsandaggregation, V_population,  v_otherIndicator, V_indexNatural, V_indexCases, V_indexDeath)\n",
    "  \n",
    "  return(get(nameOfVector))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Constants and global variables\n",
    "\n",
    "The next stage is creating constants and global variables used in code. This helps in keeping order in code. Additionally, constants help in the parametrization of the script. \n",
    "<br>\n",
    "In this script it is necessary to provides paths to all files or keep structure of files like in [HitHub](https://github.com/damiano453/PJA_COVID19_DS).\n",
    "1. CONST_WORLDBANK_FILES\n",
    "2. CONST_COUTRY_DISTANCE_FILE\n",
    "3. CONST_COUTRY_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# INIT- CONST AND GLOBAL VAR SECTION\n",
    "\n",
    "#URL - Target dataset covid19, from the European Center for Disease Prevention and Control \n",
    "CONST_ECfDP_URL <- \"https://opendata.ecdc.europa.eu/covid19/casedistribution/csv\"\n",
    "\n",
    "#files with data about population over 70\n",
    "CONST_WORLDBANK_FILES <- \"../data/WorldBank/\"\n",
    "CONST_WORLDBANK_FILES_INDICATORS <- paste0(CONST_WORLDBANK_FILES,\"indicators/\") \n",
    "\n",
    "#files with data about country distance\n",
    "CONST_COUTRY_DISTANCE_FILE <- \"../data/countries_distances.csv\"\n",
    "\n",
    "#files with data about country \n",
    "CONST_COUTRY_FILE <- \"../data/country.txt\"\n",
    "\n",
    "#key for identity country \n",
    "CONST_COUNTRY_KEY <- \"country\"\n",
    "CONST_COUNTRYID_KEY <- \"countryID\"\n",
    "\n",
    "#period form grouping and moving means  \n",
    "CONST_BASE_PERIOD <- 7\n",
    "\n",
    "#exported dataset\n",
    "CONST_EXPORT_DATASET <- c('df_COVID19Base', 'df_Country_DICT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Download and preparation of data from European Center for Disease Prevention and Control\n",
    "\n",
    "Data is collected from European Center for Disease Prevention and Control from the following link:\n",
    "\n",
    "   `CONST_ECfDP_URL <- `https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#\n",
    "# MAIN (STAGE AREA) - EXTRACT (IMPORT) DATA SECTION\n",
    "#\n",
    "#######################################################\n",
    "\n",
    "\n",
    "###############################\n",
    "# MAIN (STAGE AREA) - EXTRACT MAIN COVID 19 SET FROM URL the European Center for Disease Prevention and Control \n",
    "#download the dataset from the website to a local temporary file\n",
    "#read the Dataset sheet into “R”. The dataset will be called \"data\".\n",
    "data_m00 <- read.csv(CONST_ECfDP_URL, na.strings = \"\", fileEncoding = \"UTF-8-BOM\")\n",
    "\n",
    "#change name of colummn to identity \n",
    "setnames(data_m00, \"countriesAndTerritories\",  CONST_COUNTRY_KEY)\n",
    "setnames(data_m00, \"countryterritoryCode\",  CONST_COUNTRYID_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder in localization `CONST_WORLDBANK_FILES`contains additional files with information connected with population and GDB in every country. Data were collected from [World Bank](https://www.worldbank.org/). \n",
    "<br>Variables not used in further code are deleted immediately, to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# MAIN (STAGE AREA) - EXTRACT INDICATOR SET (POPOULATION, GDP) FROM FILEs previusly download from WorldBank site \n",
    "\n",
    "#add dataSet obout from WorldBank file \n",
    "data_df <- dir_ls(path = CONST_WORLDBANK_FILES , regexp = \".xls\")  %>%\n",
    "map_df(read_excel, .id = \"fileName\")\n",
    "\n",
    "#filter date only form filter colummn and 2018 year \n",
    "df_WordBank <- data_df[,c('fileName',\"Country Name\",\"Country Code\",\"VALUE\")]\n",
    "\n",
    "#transform WorldBank dataSet to add group sex and age \n",
    "df_WordBank <- mutate(df_WordBank, indicatorName= gsub(CONST_WORLDBANK_FILES,'', fileName))\n",
    "df_WordBank <- mutate(df_WordBank, indicatorName= gsub(\".xls\",'', indicatorName))\n",
    "\n",
    "#change name of colummn to identity \n",
    "setnames(df_WordBank, \"Country Name\",  CONST_COUNTRY_KEY)\n",
    "setnames(df_WordBank, \"Country Code\",  CONST_COUNTRYID_KEY)\n",
    "\n",
    "#transform WorldBank dataSet, pivot transformation\n",
    "df_WordBank_PSum <- cast(df_WordBank, countryID ~ indicatorName, value=\"VALUE\")\n",
    "\n",
    "#clear variables\n",
    "rm(data_df)\n",
    "rm(df_WordBank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collected from [World Bank](https://www.worldbank.org/) are added to variable (type: dataFrame) called `df_Country_00`. Additionally in this place column names are added.\n",
    "<br>\n",
    "Moreover, every name is numerated. This helps in further debugging of code during coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# MAIN (STAGE AREA) - EXTRACT COUNTRY SET FROM FILE previusly download from gitHUB site \n",
    "\n",
    "#add dataSet with specific info about Country 'capital','region','subregion','borders','area','latlng'\n",
    "df_Country_00 <- jsonify::from_json(CONST_COUTRY_FILE)\n",
    "\n",
    "#change name of column with country_id (key to join) \n",
    "setnames(df_Country_00, \"cca3\",  CONST_COUNTRYID_KEY)\n",
    "setnames(df_Country_00, \"cca2\",  \"countryGeoID\")\n",
    "\n",
    "#change name of column with colection latlng\n",
    "setnames(df_Country_00, \"latlng\",  paste0('c_', 'latlng'))\n",
    "\n",
    "#change column name with neighbors grup\n",
    "setnames(df_Country_00, \"borders\", \"c_neighbors\"  )\n",
    "\n",
    "#add (rebiuild) name of country\n",
    "df_Country_00 <- cbind(df_Country_00, df_Country_00$name[1])\n",
    "df_Country_00 <- cbind(df_Country_00, df_Country_00$name[2])\n",
    "setnames(df_Country_00, \"common\",  \"countryCommonName\")\n",
    "setnames(df_Country_00, \"official\", \"countryOfficialName\")\n",
    "\n",
    "#rebuild vector data 'latlng' to singel data'lat' and 'lng'\n",
    "for (i in seq.int(nrow(df_Country_00))) {\n",
    "  df_Country_00[i,c('lat')] <- df_Country_00$c_latlng[[i]][1]\n",
    "  df_Country_00[i,c('lng')] <- df_Country_00$c_latlng[[i]][2] \n",
    "}\n",
    "\n",
    "#add new colection column c_region, c_subregion \n",
    "df_Country_00 <- f_collapseColumns2Colection(df_Country_00, 'region' , CONST_COUNTRYID_KEY, 'c_region')\n",
    "df_Country_00 <- f_collapseColumns2Colection(df_Country_00, 'subregion' , CONST_COUNTRYID_KEY, 'c_subregion')\n",
    "\n",
    "#add colunm to agregate all data\n",
    "df_Country_00$allGroup <- \"All\"\n",
    "\n",
    "\n",
    "#zoatawiem c lat i zminiamy na c border\n",
    "df_Country_01 <- df_Country_00[, c(\"countryID\",  \"countryGeoID\",             \n",
    "                                   \"countryCommonName\", \"countryOfficialName\",                                 \n",
    "                                   \"independent\",\n",
    "                                   \"capital\",\n",
    "                                   \"c_neighbors\",\n",
    "                                   \"area\",                         \n",
    "                                   \"c_latlng\" ,\"lat\", \"lng\",                 \n",
    "                                   \"region\", \"c_region\",           \n",
    "                                   \"subregion\",\"c_subregion\",\n",
    "                                   \"allGroup\" )]\n",
    "\n",
    "#clear variables\n",
    "rm(df_Country_00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is very important in map creation. All distances between countries are collected from file: \"/data/countries_distances.csv\". This helps in generating maps published in the `Analytics` section. The process of generating is presented in scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#MAIN (STAGE AREA) - EXTRACT DISTANCE_COUNTRES SET FROM FILE previusly download from gitHUB site \n",
    "#load file with distance \n",
    "df_CountryDistance_00 <- read.csv(CONST_COUTRY_DISTANCE_FILE, na.strings = \"\", fileEncoding = \"UTF-8-BOM\")\n",
    "\n",
    "#load file with countryID \n",
    "df_CountryDistance_DICT <- df_Country_01[,c(\"countryID\", \"countryCommonName\", \"countryOfficialName\")]\n",
    "\n",
    "#join (enrichment) add countryID for left side of distance relation\n",
    "df_CountryDistance_01 <- merge(x=df_CountryDistance_00, y=df_CountryDistance_DICT, by.x = 'pays1', by.y = 'countryCommonName' , all.x=TRUE) \n",
    "setnames(df_CountryDistance_01, \"countryID\",  \"countryID_01\")\n",
    "df_CountryDistance_01 <- merge(x=df_CountryDistance_01, y=df_CountryDistance_DICT, by.x = 'pays1', by.y = 'countryOfficialName' , all.x=TRUE)\n",
    "setnames(df_CountryDistance_01, \"countryID\",  \"countryID_02\")\n",
    "\n",
    "df_CountryDistance_01 <- df_CountryDistance_01[, c('pays1', 'pays2', 'dist', 'countryID_01','countryID_02')]\n",
    "df_CountryDistance_01 <- unite(df_CountryDistance_01, 'countryID_LEFT' , c('countryID_01','countryID_02'))\n",
    "df_CountryDistance_01$countryID_LEFT <- gsub('NA_', '', df_CountryDistance_01$countryID_LEFT)\n",
    "df_CountryDistance_01$countryID_LEFT <- substr(df_CountryDistance_01$countryID_LEFT,1,3)\n",
    "\n",
    "#coutryID exeption\n",
    "df_CountryDistance_01[df_CountryDistance_01$pays1==\"Macedonia\",]$countryID_LEFT <- \"MKD\"\n",
    "df_CountryDistance_01[df_CountryDistance_01$pays1==\"Tobago\",]$countryID_LEFT <- \"TTO\"\n",
    "df_CountryDistance_01[df_CountryDistance_01$pays1==\"UK\",]$countryID_LEFT <- \"GBR\"\n",
    "df_CountryDistance_01[df_CountryDistance_01$pays1==\"USA\",]$countryID_LEFT <- \"USA\"\n",
    "\n",
    "#join (enrichment) add countryID for right side of distance relation\n",
    "df_CountryDistance_01_RIGHT<- unique(df_CountryDistance_01[,c('pays1', 'countryID_LEFT')])\n",
    "setnames(df_CountryDistance_01_RIGHT, \"countryID_LEFT\",  \"countryID_RIGHT\")\n",
    "df_CountryDistance_02 <- merge(x=df_CountryDistance_01, y=df_CountryDistance_01_RIGHT, by.x = 'pays2', by.y = 'pays1' , all.x=TRUE) \n",
    "\n",
    "#finall distance set\n",
    "setnames(df_CountryDistance_02, \"pays1\",  \"countryName_LEFT\")\n",
    "setnames(df_CountryDistance_02, \"pays2\",  \"countryName_RIGHT\")\n",
    "\n",
    "#coutryID REJECT\n",
    "df_CountryDistance_REJECT<- df_CountryDistance_02[(df_CountryDistance_02$countryID_LEFT=='NA')|(df_CountryDistance_02$countryID_RIGHT=='NA'),]\n",
    "df_CountryDistance_02 <- df_CountryDistance_02[(df_CountryDistance_02$countryID_LEFT!='NA')&(df_CountryDistance_02$countryID_RIGHT!='NA'),]\n",
    "\n",
    "\n",
    "for (x_distance in c(300,500,1000)) {\n",
    "df_CountryDistance_02_01 <- mutate(df_CountryDistance_02, groupDistance=ifelse(dist < x_distance, paste0(x_distance,countryID_LEFT),0))\n",
    "df_CountryDistance_02_01 <- df_CountryDistance_02_01[df_CountryDistance_02_01$groupDistance!=0,]\n",
    "df_CountryDistance_02_01 <- f_collapseColumns2Colection(df_CountryDistance_02_01, \"groupDistance\" ,\"countryID_RIGHT\", \"c_groupDistance\")\n",
    "df_CountryDistance_02_01 <- unique(df_CountryDistance_02_01[,c(\"countryID_LEFT\",\"c_groupDistance\")])\n",
    "df_CountryDistance_DICT <- merge(x=df_CountryDistance_DICT, y=df_CountryDistance_02_01, by.x = 'countryID', by.y = 'countryID_LEFT' , all.x=TRUE) \n",
    "setnames(df_CountryDistance_DICT, \"c_groupDistance\",  paste0(\"c_groupDistance\", x_distance)) \n",
    "}\n",
    "df_CountryDistance_DICT <- df_CountryDistance_DICT %>% select(-matches(\"Name$\"))\n",
    "#clear variables\n",
    "rm(df_CountryDistance_00)\n",
    "rm(df_CountryDistance_01)\n",
    "rm(df_CountryDistance_01_RIGHT)\n",
    "rm(df_CountryDistance_02)\n",
    "rm(df_CountryDistance_02_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of statistics counting is shown in this part. Results are used in next script.\n",
    "<br>\n",
    "At the beginning data sets prepared sooner are connected in one. The final set contains information about the population, number of illnesses, deaths, and distances between countries. Additionally, datasets contain statistics such as:\n",
    "1. Number of death from 7th day counting from first death (in the 7-day interval)\n",
    "2. Number of death from 30th day counting from first death (in the 30-day interval)\n",
    "\n",
    "\n",
    "Additionally, statistics are divided for:\n",
    "1. all population\n",
    "2. women, men and cumulated (both women and men) above 70 years old\n",
    "3. women, men and cumulated (both women and men) above 80 years old \n",
    "\n",
    "\n",
    "All statistics are used in further scripts used for data visualization.\n",
    "<br>\n",
    "The main goal was to show objective data comparison between countries with different numbers of people. In many cases, the difference is higher than 100%. To ensure about rationality number of deaths and illnesses was counted for 100k people in every country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#\n",
    "# MAIN - TRANSFORM (ENRICHMENT) DATA SECTION\n",
    "#\n",
    "#######################################################\n",
    "\n",
    "#TRANSFORM JOIN country set with distance set\n",
    "df_Country_10 <- df_Country_01\n",
    "rm(df_Country_01)\n",
    "\n",
    "#TRANSFORM JOIN country set with data about population from WorldBank\n",
    "df_Country_11 <- merge(x=df_Country_10, y=df_WordBank_PSum, by = CONST_COUNTRYID_KEY, all=FALSE)\n",
    "rm(df_WordBank_PSum)\n",
    "rm(df_Country_10)\n",
    "\n",
    "#TRANSFORM JOIN country set with data about population from WorldBank\n",
    "df_Country_12 <- merge(x=df_Country_11, y=df_CountryDistance_DICT, by = CONST_COUNTRYID_KEY, all=FALSE)\n",
    "rm(df_CountryDistance_DICT)\n",
    "rm(df_Country_11)\n",
    "\n",
    "#JOIN base data about coronavirus with data about country\n",
    "data_m01 <- merge(x=data_m00, y=df_Country_12, by = CONST_COUNTRYID_KEY, all.x=TRUE)\n",
    "rm(data_m00)\n",
    "\n",
    "##TRANSFORM dateRep is not null and coutry_id is not null\n",
    "data_m01_REJECT <- data_m01[is.na(data_m01$dateRep) | is.na(data_m01$countryID) | is.na(data_m01$countryOfficialName),]\n",
    "data_m01 <- data_m01[!is.na(data_m01[,'dateRep']),]\n",
    "data_m01 <- data_m01[!is.na(data_m01[,CONST_COUNTRYID_KEY]),]\n",
    "\n",
    "#TRANSFORM remove not use column\n",
    "data_m01$continentExp <- NULL\n",
    "data_m01$geoId <- NULL\n",
    "\n",
    "#TRANSFORM population data to numeric\n",
    "setnames(data_m01, \"popData2019\",  \"population2018_A\")\n",
    "data_m01$population2018_A <-as.numeric(data_m01$population2018_A) \n",
    "\n",
    "#TRANSFORM age group over 80 (M- male, F-fmale)\n",
    "data_m01 <- mutate(data_m01,population2018_F_80=ceiling(population2018_A*F_80/100))\n",
    "data_m01 <- mutate(data_m01,population2018_M_80=ceiling(population2018_A*M_80/100))\n",
    "data_m01 <- mutate(data_m01,population2018_A_80=population2018_F_80+population2018_M_80)\n",
    "\n",
    "#TRANSFORM age group over 70\n",
    "data_m01 <- mutate(data_m01,population2018_F_70=ceiling(population2018_A * (F_70_74+F_75_79)/100)+population2018_F_80)\n",
    "data_m01 <- mutate(data_m01,population2018_M_70=ceiling(population2018_A * (M_70_74+M_75_79)/100)+population2018_M_80)\n",
    "data_m01 <- mutate(data_m01,population2018_A_70=population2018_F_70+population2018_M_70)\n",
    "\n",
    "#TRANSFORM remove not need columns\n",
    "data_m01 <- data_m01 %>% select(-matches(\"^F_\"))\n",
    "data_m01 <- data_m01 %>% select(-matches(\"^M_\"))\n",
    "\n",
    "#TRANSFORM transform string date raporting to date format\n",
    "data_m01 <- mutate(data_m01, dateReport1DayNatural = as.Date(dateRep, \"%d/%m/%Y\"))\n",
    "#data_m01$dateReport1DayNatural <- as.Date(data_m01$dateReport1DayNatural) \n",
    "data_m01$dateRep <-NULL\n",
    "\n",
    "#TRANSFORM  first indexys natural\n",
    "#days index\n",
    "data_m01$index1DayNatural <- yday(data_m01$dateReport1DayNatural)\n",
    "#week index\n",
    "data_m01$index7DayNatural <- week(data_m01$dateReport1DayNatural)\n",
    "#month index\n",
    "data_m01$index1MonthNatural <- month(data_m01$dateReport1DayNatural)\n",
    "#month index\n",
    "data_m01$index1YearNatural <- year(data_m01$dateReport1DayNatural)\n",
    "data_m01$day <-NULL\n",
    "data_m01$month <-NULL\n",
    "data_m01$year <-NULL\n",
    "\n",
    "#TRANSFORM add culative sum of death and cases \n",
    "#change name of death column\n",
    "setnames(data_m01, \"deaths\", \"deaths1DayNatural\")\n",
    "setnames(data_m01, \"cases\", \"cases1DayNatural\")\n",
    "data_m01$deaths1DayNatural <- as.numeric(data_m01$deaths1DayNatural)\n",
    "data_m01$cases1DayNatural <- as.numeric(data_m01$cases1DayNatural)\n",
    "\n",
    "#TRANSFORM add column with cumulativ sum of death \n",
    "data_m01 <- mutate(group_by_at(data_m01,CONST_COUNTRYID_KEY), cumSumDeath1DayNatural=order_by(dateReport1DayNatural, cumsum(deaths1DayNatural)))\n",
    "#add column with roll mean of death \n",
    "data_m01 <- data_m01 %>% mutate(mmeanDeath1DayNatural=order_by(dateReport1DayNatural, rollmean(deaths1DayNatural, k = CONST_BASE_PERIOD, fill = 0, align = \"right\")))\n",
    "#add column with summary,avg, quantile of death during week\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index7DayNatural\")), sumDeaths7DayNatural = sum(deaths1DayNatural, na.rm = TRUE))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index7DayNatural\")), avgDeaths7DayNatural = round(mean(deaths1DayNatural, na.rm = TRUE)))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index7DayNatural\")), quanDeaths7DayNatural = list(quantile(deaths1DayNatural,type = 1, na.rm = TRUE)))\n",
    "#add column with summary,avg, quantile of death during month\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index1MonthNatural\")), sumDeaths1MonthNatural = sum(deaths1DayNatural, na.rm = TRUE))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index1MonthNatural\")), avgDeaths1MonthNatural = round(mean(deaths1DayNatural, na.rm = TRUE)))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index1MonthNatural\")), quanDeaths1MonthNatural = list(quantile(deaths1DayNatural,type = 1, na.rm = TRUE)))\n",
    "\n",
    "#TRANSFORM  add column with cumulativ sum of cases\n",
    "data_m01 <- mutate(group_by_at(data_m01,CONST_COUNTRYID_KEY), cumSumCases1DayNatural=order_by(dateReport1DayNatural, cumsum(cases1DayNatural)))\n",
    "#add column with roll mean of cases\n",
    "data_m01 <- data_m01 %>% mutate(mmeanCases1DayNatural=order_by(dateReport1DayNatural, rollmean(cases1DayNatural, k = CONST_BASE_PERIOD, fill = 0, align = \"right\")))\n",
    "#add column with summary,avg, quantile of cases during week\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index7DayNatural\")), sumCases7DayNatural = sum(cases1DayNatural, na.rm = TRUE))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index7DayNatural\")), avgCases7DayNatural = round(mean(cases1DayNatural, na.rm = TRUE),0))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index7DayNatural\")), quanCases7DayNatural = list(quantile(cases1DayNatural,type = 1, na.rm = TRUE)))\n",
    "#add column with summary,avg, quantile of cases during month\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index1MonthNatural\")), sumCases1MonthNatural = sum(cases1DayNatural, na.rm = TRUE))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index1MonthNatural\")), avgCases1MonthNatural = round(mean(cases1DayNatural, na.rm = TRUE)))\n",
    "data_m01 <- mutate(group_by_at(data_m01, c(CONST_COUNTRYID_KEY, \"index1MonthNatural\")), quanCases1MonthNatural = list(quantile(cases1DayNatural,type = 1, na.rm = TRUE)))\n",
    "\n",
    "\n",
    "#TRANSFORM  add indexes (how many days is after the event)\n",
    "data_m01 <- mutate(group_by(data_m01,country), index1Day1Death=order_by(dateReport1DayNatural, cumsum(ifelse(cumSumDeath1DayNatural>0, 1, 0))))\n",
    "data_m01 <- mutate(group_by(data_m01,country), index1Day1Case=order_by(dateReport1DayNatural, cumsum(ifelse( cumSumCases1DayNatural >0, 1, 0))))\n",
    "\n",
    "data_m01 <- mutate(group_by(data_m01,country), index1Day1cumSumDeathP1mAll=order_by(dateReport1DayNatural, cumsum(ifelse(cumSumDeath1DayNatural >(1*(population2018_A/(10^6))), 1, 0))))\n",
    "data_m01 <- mutate(group_by(data_m01,country), index1Day10cumSumCaseP1mAll=order_by(dateReport1DayNatural, cumsum(ifelse( cumSumCases1DayNatural >(10*(population2018_A/(10^6))), 1, 0))))\n",
    "\n",
    "data_m01 <- mutate(group_by(data_m01,country), index1Day1cumSumDeathP100t_A_70=order_by(dateReport1DayNatural, cumsum(ifelse(cumSumDeath1DayNatural >(1*(population2018_A_70/(10^5))), 1, 0))))\n",
    "data_m01 <- mutate(group_by(data_m01,country), index1Day10cumSumCaseP100t_A_70=order_by(dateReport1DayNatural, cumsum(ifelse( cumSumCases1DayNatural >(10*(population2018_A_70/(10^5))), 1, 0))))\n",
    "\n",
    "\n",
    "#TRANSFORM  find natural weekend siutable to first day of index (group of index)\n",
    "v_Indexes_Week = c(\"index1Day1Death\", \"index1Day1Case\", \"index1Day1cumSumDeathP1mAll\", \"index1Day10cumSumCaseP1mAll\", \"index1Day1cumSumDeathP100t_A_70\", \"index1Day10cumSumCaseP100t_A_70\")\n",
    "for ( x_indexName in v_Indexes_Week) {\n",
    "  # select data when value of index is equel 1, and siutable for dzis date natural week number of week \n",
    "  df_week_1 <- data_m01[which((data_m01[,x_indexName])==1),c(CONST_COUNTRYID_KEY,\"index7DayNatural\")]\n",
    "  setnames(df_week_1, \"index7DayNatural\",  \"week_1\")\n",
    "  #number of siutble natural week decrease (- 1), it is value which will by use to counting number of weekend \n",
    "  df_week_1['week_1'] <- df_week_1$week_1 - 1 \n",
    "  #counting siutable weekend to the index\n",
    "  data_m01 <- merge(x=data_m01, y=df_week_1, by = CONST_COUNTRYID_KEY, all=FALSE)\n",
    "  x_indexWeekName <- str_replace(x_indexName, \"1Day\", \"7Day\")\n",
    "  data_m01[x_indexWeekName] <- data_m01[\"index7DayNatural\"] - data_m01[\"week_1\"] \n",
    "  #all weekend befor event is equal 0\n",
    "  data_m01[data_m01[,x_indexWeekName]<1,x_indexWeekName] <- 0\n",
    "  #drop technical column\n",
    "  data_m01$week_1 <- NULL\n",
    "}\n",
    "\n",
    "#TRANSFORM add data from previus and next term (7day)\n",
    "#select data for first day of week\n",
    "CONST_Aggregat_Column_Death_Week <- c(\"sumCases7DayNatural\", \"avgCases7DayNatural\", \"quanCases7DayNatural\")\n",
    "CONST_Aggregat_Column_Cases_Week <- c(\"sumDeaths7DayNatural\", \"avgDeaths7DayNatural\", \"quanDeaths7DayNatural\")\n",
    "data_PrevNext7Day <- data_m01[which((data_m01$index1DayNatural%%7)==1),c(CONST_COUNTRYID_KEY,\"index7DayNatural\",CONST_Aggregat_Column_Death_Week,CONST_Aggregat_Column_Cases_Week)]\n",
    "\n",
    "#internal function to marge pivius and next term\n",
    "mergePriVNextTermColumns <- function(data_add, columnNameSufix, yIndex2Merge ){\n",
    "  for (v_columnName in c(CONST_Aggregat_Column_Death_Week, CONST_Aggregat_Column_Cases_Week)) {\n",
    "      setnames(data_add, v_columnName ,  paste0(v_columnName, columnNameSufix))\n",
    "      }\n",
    "  data_add$index7DayNatural <- NULL\n",
    "\n",
    "  #merge previus term data\n",
    "  data_m01 <- merge(x=data_m01, y=data_add, by.x = c(CONST_COUNTRYID_KEY, 'index1DayNatural'), by.y = c(CONST_COUNTRYID_KEY, yIndex2Merge), all.x = TRUE)\n",
    "  return(data_m01)\n",
    "}\n",
    "\n",
    "#change index up for merging privius term\n",
    "data_Prev7Day <- mutate(data_PrevNext7Day,index7DayNaturalPrev=index7DayNatural+1)\n",
    "data_m01 <- mergePriVNextTermColumns(data_Prev7Day, \"Prev7Day\", \"index7DayNaturalPrev\")\n",
    "\n",
    "#change index down form merging next term\n",
    "data_Next7Day <- mutate(data_PrevNext7Day,index7DayNaturalNext=index7DayNatural-1)\n",
    "data_m01<- mergePriVNextTermColumns(data_Next7Day, \"Next7Day\", \"index7DayNaturalNext\")\n",
    "\n",
    "#clear variables\n",
    "rm(data_PrevNext7Day)\n",
    "rm(data_Prev7Day)\n",
    "rm(data_Next7Day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, final data sets preparation is done. All data is sorted and prepared to export.\n",
    "<br>\n",
    "Here data can be exported to database, saved in file, or the next script can be started, which will use prepared variables. A good idea is to save as `*.csv` file or R standard which will allow for easier reading in other R scripts.\n",
    "<br>\n",
    "If data will be used in the same environment next sripts will use variables which were not deleted: `df_COVID19Base` and `df_Country_DICT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#\n",
    "# MAIN - LOAD (EXPORT) DATA SECTION\n",
    "#\n",
    "#######################################################\n",
    "\n",
    "#generate order of colums for finall data set \n",
    "#drop not used columns\n",
    "data_m01$allGroup <- NULL \n",
    "data_m01$country <-NULL\n",
    "setnames(data_m01, \"countryID\", \"PK_countryID\")\n",
    "setnames(data_m01, \"dateReport1DayNatural\", \"PK_dateReport1DayNatural\")\n",
    "\n",
    "#test column for finall order (te registered column are siutable to real column) \n",
    "columnsRegisterFALSE_data_m02_REJECT <- setdiff(f_orderColumnFinallDataSet(\"v_order_column_SUM\"), colnames(data_m01))\n",
    "                             \n",
    "#finall order columns in data set\n",
    "data_m02 <- data_m01[ ,f_orderColumnFinallDataSet(\"v_order_column_SUM\")]                              \n",
    "\n",
    "#create dict dataSet with all country \n",
    "df_Country_DICT <- data_m02[,  c(f_orderColumnFinallDataSet(\"v_country_SUM\"))]\n",
    "#only UNIQue \n",
    "df_Country_DICT <- unique(df_Country_DICT)\n",
    "#PK_coutryID has to by not null \n",
    "df_Country_DICT <- df_Country_DICT[!is.na(df_Country_DICT$PK_countryID),]\n",
    "#one name of country has to by not null \n",
    "df_Country_DICT <- df_Country_DICT[(!is.na(df_Country_DICT$countryCommonName))|(!is.na(df_Country_DICT$countryOfficialName)),]\n",
    "\n",
    "#clear variables\n",
    "rm(data_m01)\n",
    "\n",
    "\n",
    "# export data to databas or other packages\n",
    "df_COVID19Base <- data_m02\n",
    "df_Country_DICT <-df_Country_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, final memory cleaning is implemented. It was coded in 2 steps:\n",
    "1. Cleaning list of variables `rm()`\n",
    "2. Getting memory free `gc()`\n",
    "\n",
    "Command `rm()` removes variables, but memory is still not free. To free memory it is necessary to add `gc()` command after `rm()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#\n",
    "# FINAL SECTION\n",
    "#\n",
    "#######################################################\n",
    "#Remove all variables without CAST_EXPORT_DATASET\n",
    "ls_VariablesToRm <- NULL\n",
    "ls_VariablesToRm <- ls()\n",
    "ls_VariablesToRm <-ls_VariablesToRm[!ls_VariablesToRm %in% ls_VariablesToRm[(ls_VariablesToRm %in% CONST_EXPORT_DATASET) | (ls_VariablesToRm %like% '*_REJECT')]]\n",
    "rm(list=ls_VariablesToRm)\n",
    "gc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
